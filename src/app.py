"""Streamlit app: upload files, ingest into Chroma, ask queries."""
import streamlit as st
from dotenv import load_dotenv
import os
import uuid
import time
import logging
import json
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

from ingest import save_uploaded_file, extract_text_from_file, chunk_text
from vector_store import VectorStore
from retriever import build_prompt
from llm_adapter import generate, get_llm_status

load_dotenv()

CHROMA_DIR = os.getenv("CHROMA_PERSIST_DIR", "./chroma_db")
CONVERSATION_HISTORY_FILE = os.getenv("CONVERSATION_HISTORY_FILE", "./conversation_history.json")
CONVERSATION_THREADS_FILE = os.getenv("CONVERSATION_THREADS_FILE", "./conversation_threads.json")
MAX_CONVERSATION_THREADS = 5


@st.cache_resource
def get_store():
    return VectorStore(persist_directory=CHROMA_DIR)


def save_conversation_history(history):
    """ä¿å­˜å¯¹è¯å†å²åˆ°æœ¬åœ°æ–‡ä»¶
    
    Args:
        history: å¯¹è¯å†å²åˆ—è¡¨
    """
    try:
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(CONVERSATION_HISTORY_FILE), exist_ok=True)
        
        # ä¿å­˜å¯¹è¯å†å²
        with open(CONVERSATION_HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
        logger.info(f"å¯¹è¯å†å²å·²ä¿å­˜åˆ° {CONVERSATION_HISTORY_FILE}")
        return True
    except Exception as e:
        logger.error(f"ä¿å­˜å¯¹è¯å†å²å¤±è´¥: {e}")
        return False


def load_conversation_history():
    """ä»æœ¬åœ°æ–‡ä»¶åŠ è½½å¯¹è¯å†å²
    
    Returns:
        å¯¹è¯å†å²åˆ—è¡¨ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–åŠ è½½å¤±è´¥åˆ™è¿”å›åŒ…å«æ¬¢è¿æ¶ˆæ¯çš„é»˜è®¤åˆ—è¡¨
    """
    try:
        if os.path.exists(CONVERSATION_HISTORY_FILE):
            with open(CONVERSATION_HISTORY_FILE, 'r', encoding='utf-8') as f:
                history = json.load(f)
                logger.info(f"ä» {CONVERSATION_HISTORY_FILE} åŠ è½½äº† {len(history)} æ¡å¯¹è¯å†å²")
                return history
        else:
            logger.info(f"å¯¹è¯å†å²æ–‡ä»¶ä¸å­˜åœ¨: {CONVERSATION_HISTORY_FILE}")
    except Exception as e:
        logger.error(f"åŠ è½½å¯¹è¯å†å²å¤±è´¥: {e}")
    
    # è¿”å›é»˜è®¤å¯¹è¯å†å²
    return [
        {
            "role": "assistant",
            "content": "æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„AIåŠ©æ‰‹ã€‚è¯·ä¸Šä¼ æ–‡ä»¶å¹¶æé—®ï¼Œæˆ‘å°†åŸºäºæ–‡ä»¶å†…å®¹ä¸ºæ‚¨æä¾›ç­”æ¡ˆã€‚",
            "timestamp": "æ¬¢è¿æ¶ˆæ¯"
        }
    ]


def add_conversation_to_vector_store(history, store=None):
    """å°†å¯¹è¯å†å²æ·»åŠ åˆ°å‘é‡åº“ä¸­
    
    Args:
        history: å¯¹è¯å†å²åˆ—è¡¨
        store: VectorStoreå®ä¾‹ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨è·å–
    
    Returns:
        æ·»åŠ åˆ°å‘é‡åº“çš„æ–‡æ¡£æ•°é‡
    """
    if store is None:
        store = get_store()
    
    # å‡†å¤‡å¯¹è¯å†å²æ–‡æ¡£
    conversation_docs = []
    
    # éå†å¯¹è¯å†å²ï¼Œå°†é—®ç­”å¯¹ç»„åˆæˆæ–‡æ¡£
    i = 0
    while i < len(history):
        # è·³è¿‡æ¬¢è¿æ¶ˆæ¯å’Œå•ç‹¬çš„åŠ©æ‰‹/ç”¨æˆ·æ¶ˆæ¯
        if history[i].get("role") == "user" and i + 1 < len(history) and history[i + 1].get("role") == "assistant":
            user_message = history[i]
            assistant_message = history[i + 1]
            
            # ç»„åˆé—®ç­”å¯¹ä¸ºä¸€ä¸ªæ–‡æ¡£
            conversation_text = f"ç”¨æˆ·é—®é¢˜: {user_message.get('content', '')}\n\nAIå›ç­”: {assistant_message.get('content', '')}"
            
            # åˆ›å»ºæ–‡æ¡£
            doc = {
                "id": f"conversation_{uuid.uuid4()}",
                "text": conversation_text,
                "metadata": {
                    "source": "conversation_history",
                    "timestamp": user_message.get("timestamp", ""),
                    "type": "conversation_pair"
                }
            }
            conversation_docs.append(doc)
            
            # è·³è¿‡å·²å¤„ç†çš„åŠ©æ‰‹æ¶ˆæ¯
            i += 2
        else:
            i += 1
    
    # å¦‚æœæœ‰å¯¹è¯æ–‡æ¡£ï¼Œæ·»åŠ åˆ°å‘é‡åº“
    if conversation_docs:
        try:
            logger.info(f"å‡†å¤‡å°† {len(conversation_docs)} æ¡å¯¹è¯å†å²æ·»åŠ åˆ°å‘é‡åº“")
            store.add_documents(conversation_docs)
            logger.info(f"æˆåŠŸå°† {len(conversation_docs)} æ¡å¯¹è¯å†å²æ·»åŠ åˆ°å‘é‡åº“")
            return len(conversation_docs)
        except Exception as e:
            logger.error(f"å°†å¯¹è¯å†å²æ·»åŠ åˆ°å‘é‡åº“å¤±è´¥: {e}")
            return 0
    
    logger.info("æ²¡æœ‰æ‰¾åˆ°å¯æ·»åŠ åˆ°å‘é‡åº“çš„å¯¹è¯å†å²")
    return 0


def save_conversation_threads(threads):
    """ä¿å­˜å¯¹è¯çº¿ç¨‹åˆ°æœ¬åœ°æ–‡ä»¶
    
    Args:
        threads: å¯¹è¯çº¿ç¨‹å­—å…¸
    """
    try:
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(CONVERSATION_THREADS_FILE), exist_ok=True)
        
        # ä¿å­˜å¯¹è¯çº¿ç¨‹
        with open(CONVERSATION_THREADS_FILE, 'w', encoding='utf-8') as f:
            json.dump(threads, f, ensure_ascii=False, indent=2)
        logger.info(f"å¯¹è¯çº¿ç¨‹å·²ä¿å­˜åˆ° {CONVERSATION_THREADS_FILE}")
        return True
    except Exception as e:
        logger.error(f"ä¿å­˜å¯¹è¯çº¿ç¨‹å¤±è´¥: {e}")
        return False


def load_conversation_threads():
    """ä»æœ¬åœ°æ–‡ä»¶åŠ è½½å¯¹è¯çº¿ç¨‹
    
    Returns:
        å¯¹è¯çº¿ç¨‹å­—å…¸ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–åŠ è½½å¤±è´¥åˆ™è¿”å›ç©ºå­—å…¸
    """
    try:
        if os.path.exists(CONVERSATION_THREADS_FILE):
            with open(CONVERSATION_THREADS_FILE, 'r', encoding='utf-8') as f:
                threads = json.load(f)
                logger.info(f"ä» {CONVERSATION_THREADS_FILE} åŠ è½½äº† {len(threads)} ä¸ªå¯¹è¯çº¿ç¨‹")
                return threads
        else:
            logger.info(f"å¯¹è¯çº¿ç¨‹æ–‡ä»¶ä¸å­˜åœ¨: {CONVERSATION_THREADS_FILE}")
    except Exception as e:
        logger.error(f"åŠ è½½å¯¹è¯çº¿ç¨‹å¤±è´¥: {e}")
    
    # è¿”å›ç©ºå­—å…¸
    return {}


def delete_conversation_thread(thread_id):
    """åˆ é™¤æŒ‡å®šçš„å¯¹è¯çº¿ç¨‹å¹¶åŒæ­¥æ›´æ–°æœ¬åœ°å­˜å‚¨"""
    # ä»ä¼šè¯çŠ¶æ€ä¸­åˆ é™¤çº¿ç¨‹
    if thread_id in st.session_state.conversation_threads:
        del st.session_state.conversation_threads[thread_id]
        # åŒæ­¥æ›´æ–°æœ¬åœ°å­˜å‚¨
        save_conversation_threads(st.session_state.conversation_threads)
        st.info(f"åˆ é™¤å¯¹è¯çº¿ç¨‹: {thread_id}")
        return True
    else:
        st.error(f"æ‰¾ä¸åˆ°å¯¹è¯çº¿ç¨‹: {thread_id}")
        return False


def create_new_conversation_thread(threads, thread_id=None):
    """åˆ›å»ºæ–°çš„å¯¹è¯çº¿ç¨‹
    
    Args:
        threads: ç°æœ‰å¯¹è¯çº¿ç¨‹å­—å…¸
        thread_id: å¯é€‰çš„çº¿ç¨‹IDï¼Œå¦‚æœä¸æä¾›åˆ™ç”Ÿæˆæ–°ID
    
    Returns:
        (thread_id, new_thread): çº¿ç¨‹IDå’Œæ–°çº¿ç¨‹å¯¹è±¡
    """
    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§çº¿ç¨‹æ•°
    if len(threads) >= MAX_CONVERSATION_THREADS:
        logger.warning(f"å·²è¾¾åˆ°æœ€å¤§å¯¹è¯çº¿ç¨‹æ•°: {MAX_CONVERSATION_THREADS}")
        # åˆ é™¤æœ€æ—§çš„çº¿ç¨‹
        oldest_thread_id = min(threads.keys(), key=lambda k: threads[k].get('created_at', ''))
        del threads[oldest_thread_id]
        logger.info(f"åˆ é™¤äº†æœ€æ—§çš„å¯¹è¯çº¿ç¨‹: {oldest_thread_id}")
    
    # ç”Ÿæˆæ–°çš„çº¿ç¨‹ID
    if thread_id is None:
        thread_id = str(uuid.uuid4())
    
    # åˆ›å»ºæ–°çº¿ç¨‹
    new_thread = {
        'id': thread_id,
        'name': 'æ–°å¯¹è¯',
        'created_at': time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()),
        'last_updated': time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()),
        'conversation_history': [
            {
                "role": "assistant",
                "content": "æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„AIåŠ©æ‰‹ã€‚è¯·ä¸Šä¼ æ–‡ä»¶å¹¶æé—®ï¼Œæˆ‘å°†åŸºäºæ–‡ä»¶å†…å®¹ä¸ºæ‚¨æä¾›ç­”æ¡ˆã€‚",
                "timestamp": "æ¬¢è¿æ¶ˆæ¯"
            }
        ]
    }
    
    # æ·»åŠ åˆ°çº¿ç¨‹å­—å…¸
    threads[thread_id] = new_thread
    logger.info(f"åˆ›å»ºäº†æ–°çš„å¯¹è¯çº¿ç¨‹: {thread_id}")
    
    # ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶
    save_conversation_threads(threads)
    
    return thread_id, new_thread


def update_thread_name(threads, thread_id, user_question):
    """æ ¹æ®ç”¨æˆ·çš„é¦–ä¸ªæé—®æ›´æ–°çº¿ç¨‹åç§°
    
    Args:
        threads: å¯¹è¯çº¿ç¨‹å­—å…¸
        thread_id: çº¿ç¨‹ID
        user_question: ç”¨æˆ·çš„é¦–ä¸ªé—®é¢˜
    """
    if thread_id in threads:
        # æˆªå–é—®é¢˜å‰20ä¸ªå­—ç¬¦ä½œä¸ºçº¿ç¨‹åç§°
        thread_name = user_question[:20]
        if len(user_question) > 20:
            thread_name += '...'
        
        threads[thread_id]['name'] = thread_name
        threads[thread_id]['last_updated'] = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
        
        # ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶
        save_conversation_threads(threads)
        logger.info(f"æ›´æ–°äº†å¯¹è¯çº¿ç¨‹åç§°: {thread_id} -> {thread_name}")
        return True
    return False


def ingest_and_index(uploaded_files):
    """å¤„ç†å¤šä¸ªæ–‡ä»¶å¹¶ç´¢å¼•åˆ°å‘é‡æ•°æ®åº“
    
    Args:
        uploaded_files: å•ä¸ªæ–‡ä»¶æˆ–æ–‡ä»¶åˆ—è¡¨
    """
    # ç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼
    if not isinstance(uploaded_files, list):
        uploaded_files = [uploaded_files]
    
    # é™åˆ¶æœ€å¤š5ä¸ªæ–‡ä»¶
    if len(uploaded_files) > 5:
        st.error(f"æœ€å¤šåªèƒ½å¤„ç†5ä¸ªæ–‡ä»¶ï¼Œæ‚¨ä¸Šä¼ äº† {len(uploaded_files)} ä¸ªæ–‡ä»¶")
        uploaded_files = uploaded_files[:5]
    
    # æ¸…é™¤ä¸Šä¸€æ¬¡ä¸Šä¼ çš„æ–‡ä»¶å†…å®¹ç¼“å­˜
    store = get_store()
    
    # æ¸…é™¤ Streamlit ç¼“å­˜
    get_store.clear()
    
    # åˆ é™¤æ•´ä¸ªé›†åˆå¹¶é‡æ–°åˆ›å»ºï¼ˆæ›´å½»åº•ï¼‰
    store.delete_collection()
    
    # é‡æ–°è·å– VectorStore å®ä¾‹
    store = get_store()
    
    tmpdir = os.path.join(".", "uploads")
    total_docs = 0
    total_time = time.time()
    
    # æ˜¾ç¤ºè¿›åº¦
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for idx, uploaded_file in enumerate(uploaded_files):
        file_start_time = time.time()
        
        # æ›´æ–°è¿›åº¦
        progress = (idx + 1) / len(uploaded_files)
        progress_bar.progress(progress)
        status_text.text(f"æ­£åœ¨å¤„ç†æ–‡ä»¶ {idx + 1}/{len(uploaded_files)}: {uploaded_file.name}")
        
        try:
            # ä¿å­˜æ–‡ä»¶
            path = save_uploaded_file(uploaded_file, tmpdir)
            
            # æå–æ–‡æœ¬
            extract_start = time.time()
            try:
                text = extract_text_from_file(path)
                # æ£€æŸ¥æå–çš„æ–‡æœ¬æ˜¯å¦ä¸ºç©ºæˆ–å¤ªçŸ­
                if not text or len(text.strip()) < 10:
                    st.warning(f"âš ï¸ æ–‡ä»¶ {uploaded_file.name} æå–çš„æ–‡æœ¬ä¸ºç©ºæˆ–å¤ªçŸ­ï¼ˆ{len(text)} å­—ç¬¦ï¼‰ï¼Œå¯èƒ½æ— æ³•æ­£ç¡®ç´¢å¼•")
            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶ {uploaded_file.name} æ–‡æœ¬æå–å¤±è´¥: {e}")
                continue
            extract_time = time.time() - extract_start
            
            # åˆ†å—
            chunk_start = time.time()
            chunks = chunk_text(text)
            chunk_time = time.time() - chunk_start
            
            if not chunks:
                st.warning(f"âš ï¸ æ–‡ä»¶ {uploaded_file.name} æ²¡æœ‰ç”Ÿæˆä»»ä½•æ–‡æ¡£å—")
                continue
            
            # æ„å»ºæ–‡æ¡£
            docs = []
            for i, c in enumerate(chunks):
                docs.append({
                    "id": f"{uuid.uuid4()}",
                    "text": c,
                    "metadata": {
                        "source": uploaded_file.name,
                        "chunk_index": i,
                        "file_index": idx
                    },
                })
            
            # æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
            embed_start = time.time()
            store.add_documents(docs)
            embed_time = time.time() - embed_start
            
            total_docs += len(docs)
            file_time = time.time() - file_start_time
            
            # è®°å½•æ–‡ä»¶å¤„ç†ä¿¡æ¯åˆ°æ—¥å¿—
            logger.info(f"æ–‡ä»¶ {uploaded_file.name} å¤„ç†å®Œæˆ - ç”Ÿæˆ {len(docs)} ä¸ªæ–‡æ¡£å—, å¤„ç†è€—æ—¶: {file_time:.2f}ç§’")
        
        except Exception as e:
            st.error(f"å¤„ç†æ–‡ä»¶ {uploaded_file.name} æ—¶å‡ºé”™: {e}")
            import traceback
            with st.expander("é”™è¯¯è¯¦æƒ…"):
                st.code(traceback.format_exc())
            continue
    
    # å®Œæˆ
    progress_bar.progress(1.0)
    status_text.empty()
    total_time = time.time() - total_time
    
    st.success(f"âœ“ ç´¢å¼•å®Œæˆï¼å…±å¤„ç† {len(uploaded_files)} ä¸ªæ–‡ä»¶ï¼Œç”Ÿæˆ {total_docs} ä¸ªæ–‡æ¡£å—")
    # è®°å½•æ€»ä½“æ€§èƒ½ç»Ÿè®¡åˆ°æ—¥å¿—
    logger.info(f"ç´¢å¼•æ€§èƒ½ç»Ÿè®¡ - å¤„ç†æ–‡ä»¶æ•°: {len(uploaded_files)}, æ€»æ–‡æ¡£å—æ•°: {total_docs}, æ€»è€—æ—¶: {total_time:.2f}ç§’, å¹³å‡æ¯ä¸ªæ–‡ä»¶: {total_time/len(uploaded_files):.2f}ç§’")


def main():
    st.title("RAG Chat â€” Streamlit + Chroma + OpenAI-Compat/Ollama")
    
    # æ·»åŠ è‡ªå®šä¹‰CSSæ ·å¼
    st.markdown("""
    <style>
    /* å…¨å±€é‡ç½®ï¼Œé¿å…Streamlité»˜è®¤æ ·å¼å¹²æ‰° */
    body {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
        overflow: hidden; /* é˜²æ­¢é¡µé¢æ•´ä½“æ»šåŠ¨ */
    }
    
    /* é‡ç½®Streamlité»˜è®¤å®¹å™¨æ ·å¼ */
    .stApp {
        background-color: #ffffff;
        padding: 0;
        max-width: 100%;
    }
    
    /* éšè—Streamlité»˜è®¤çš„ä¾§è¾¹æ å’Œé¡µå¤´ï¼Œåªä¿ç•™å†…å®¹åŒºåŸŸ */
    header {
        display: none !important;
    }
    
    /* è°ƒæ•´ä¸»å†…å®¹åŒºåŸŸï¼Œæ·»åŠ å·¦å³è¾¹è· */
    .block-container {
        padding: 0 2rem !important;
        margin: 0 auto !important;
        max-width: 1200px !important;
    }
    
    /* é¡µé¢å¸ƒå±€æ ·å¼ - ä½¿ç”¨flexå¸ƒå±€ç¡®ä¿è¾“å…¥æ¡†åœ¨é¡¶éƒ¨ï¼Œæ¶ˆæ¯å®¹å™¨å æ»¡å‰©ä½™ç©ºé—´ */
    .main-container {
        display: flex;
        flex-direction: column;
        min-height: 100vh;
        width: 100%;
        box-sizing: border-box;
    }
    
    /* ç¡®ä¿è¾“å…¥å®¹å™¨åœ¨é¡¶éƒ¨ï¼Œå¹¶æœ‰å›ºå®šé«˜åº¦ */
    .input-container {
        position: relative;
        background-color: #ffffff;
        padding: 1rem;
        box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        width: 100%;
        box-sizing: border-box;
        z-index: 10;
    }
    
    /* å…³é”®ä¿®å¤ï¼šä½¿ç”¨ç›¸å¯¹å®šä½ç¡®ä¿å®¹å™¨ä¸ä¸»é¡µé¢æ­£ç¡®é›†æˆï¼Œå¹¶æ·»åŠ é»‘è‰²è¾¹æ¡† */
    .chat-history-wrapper {
        position: relative; /* æ”¹ä¸ºç›¸å¯¹å®šä½ */
        flex: 1; /* ä½¿ç”¨flexå¸ƒå±€å æ»¡å‰©ä½™ç©ºé—´ */
        overflow-y: auto; /* å†…å®¹è¶…è¿‡é«˜åº¦æ—¶æ˜¾ç¤ºå‚ç›´æ»šåŠ¨æ¡ */
        border: 2px solid #000000; /* å°†è¾¹æ¡†æ”¹ä¸º2pxé»‘è‰²å®çº¿ */
        border-radius: 0.5rem;
        padding: 1rem;
        background-color: #ffffff;
        box-sizing: border-box;
        z-index: 5;
        min-height: 0; /* å…è®¸flexå­å…ƒç´ ç¼©å°åˆ°å†…å®¹å¤§å° */
        max-width: 100%;
        margin: 0 auto;
    }
    
    /* ç¡®ä¿messages-containerå®Œå…¨å¡«å……wrapper */
    .messages-container {
        width: 100%;
        padding: 0;
        margin: 0;
    }
    
    /* ç¡®ä¿æ¶ˆæ¯å¡ç‰‡æ­£ç¡®æ˜¾ç¤º */
    .message-card {
        width: 100%;
        margin-bottom: 1rem;
        padding: 0.75rem;
        border-radius: 0.5rem;
        box-sizing: border-box;
        display: block;
    }
    
    /* ç”¨æˆ·æ¶ˆæ¯æ ·å¼ */
    .user-message {
        background-color: #f0f4f8;
        border-left: 4px solid #1E88E5;
    }
    
    /* åŠ©æ‰‹æ¶ˆæ¯æ ·å¼ */
    .assistant-message {
        background-color: #e3f2fd;
        border-left: 4px solid #0D47A1;
    }
    
    /* é—®ç­”æ˜¾ç¤ºåŒºåŸŸæ ·å¼ */
    .qa-display-area {
        margin-top: 1rem;
        padding: 1rem;
        background-color: #ffffff;
        border-radius: 0.5rem;
        box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);
        width: 100%;
        box-sizing: border-box;
    }
    
    /* æ¥æºä¿¡æ¯æ ·å¼ */
    .sources-info {
        margin-top: 0.5rem;
        padding: 0.5rem;
        background-color: #f5f5f5;
        border-radius: 0.25rem;
        font-size: 0.875rem;
    }
    
    .user-message {
        background-color: #f0f9ff;
        border-left: 4px solid #3b82f6;
    }
    
    .assistant-message {
        background-color: #f8fafc;
        border-left: 4px solid #10b981;
    }
    
    /* è‡ªå®šä¹‰è¾“å…¥æ¡†å’ŒæŒ‰é’®ç»„åˆæ ·å¼ */
    .custom-input-wrapper {
        position: relative;
        width: 100%;
        max-width: 800px;
        margin: 0 auto;
    }
    
    .stTextInput > div:first-child {
        width: 100%;
    }
    
    .stTextInput input {
        width: 100%;
        padding-right: 60px; /* ä¸ºå³ä¾§æŒ‰é’®ç•™å‡ºç©ºé—´ */
        padding-top: 8px;
        padding-bottom: 8px;
        padding-left: 12px;
        border-radius: 8px;
    }
    
    /* è‡ªå®šä¹‰æŒ‰é’®æ ·å¼ */
    .stButton > button {
        background-color: #2196F3;
        color: white;
        border: none;
        padding: 8px 16px;
        border-radius: 4px;
        cursor: pointer;
    }
    
    .stButton > button:hover {
        background-color: #1565C0;
    }
    
    .stButton > button:active {
        background-color: #0D47A1;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # æ·»åŠ Streamlitç»„ä»¶é€šä¿¡çš„åŸºç¡€è„šæœ¬
    st.markdown("""
    <script>
        // ç¡®ä¿Streamlitç»„ä»¶APIåŠ è½½å®Œæˆ
        function ensureStreamlitReady() {
            if (window.parent.Streamlit) {
                window.parent.Streamlit.setComponentReady();
                return true;
            }
            return false;
        }
        
        // åˆå§‹åŒ–æ—¶å°è¯•ç¡®ä¿Streamlitå‡†å¤‡å°±ç»ª
        ensureStreamlitReady();
        
        // æä¾›ç»Ÿä¸€çš„è®¾ç½®session_stateå€¼çš„å‡½æ•°
        function setStreamlitState(key, value) {
            try {
                // ä¼˜å…ˆä½¿ç”¨Streamlitç»„ä»¶API
                if (window.parent.Streamlit && window.parent.Streamlit.setComponentValue) {
                    window.parent.Streamlit.setComponentValue(key, value);
                    return true;
                }
                // å¤‡é€‰æ–¹æ¡ˆï¼šä½¿ç”¨è‡ªå®šä¹‰äº‹ä»¶
                if (window.parent && window.parent.document) {
                    window.parent.document.dispatchEvent(
                        new CustomEvent('streamlit:setComponentValue', {
                            detail: {key: key, value: value}
                        })
                    );
                    return true;
                }
                return false;
            } catch (error) {
                console.error('è®¾ç½®StreamlitçŠ¶æ€å¤±è´¥:', error);
                return false;
            }
        }
        
        // æš´éœ²ç»™å…¨å±€ä½¿ç”¨
        window.setStreamlitState = setStreamlitState;
    </script>
    """, unsafe_allow_html=True)

    # åˆå§‹åŒ–å¯¹è¯çº¿ç¨‹å’Œå½“å‰çº¿ç¨‹ID
    if "conversation_threads" not in st.session_state:
        st.session_state.conversation_threads = load_conversation_threads()
    
    if "current_thread_id" not in st.session_state:
        # å¦‚æœæ²¡æœ‰çº¿ç¨‹ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çº¿ç¨‹
        if not st.session_state.conversation_threads:
            thread_id, _ = create_new_conversation_thread(st.session_state.conversation_threads)
            st.session_state.current_thread_id = thread_id
        else:
            # å¦åˆ™ä½¿ç”¨æœ€æ–°çš„çº¿ç¨‹
            st.session_state.current_thread_id = max(
                st.session_state.conversation_threads.keys(),
                key=lambda k: st.session_state.conversation_threads[k].get('last_updated', '')
            )
    
    # åˆå§‹åŒ–è‡ªå®šä¹‰æŒ‰é’®ç‚¹å‡»çŠ¶æ€
    if 'custom_ask_clicked' not in st.session_state:
        st.session_state.custom_ask_clicked = False
    
    # åˆå§‹åŒ–åˆ é™¤å¯¹è¯ç›¸å…³çŠ¶æ€
    if 'thread_to_delete' not in st.session_state:
        st.session_state.thread_to_delete = None
    if 'show_delete_confirm' not in st.session_state:
        st.session_state.show_delete_confirm = False
    
    # æ˜¾ç¤ºåˆ é™¤ç¡®è®¤å¯¹è¯æ¡†
    if st.session_state.show_delete_confirm and st.session_state.thread_to_delete:
        with st.sidebar:
            thread_name = st.session_state.conversation_threads.get(
                st.session_state.thread_to_delete, {}).get('name', 'æœªçŸ¥å¯¹è¯')
            st.error(f"ç¡®å®šè¦åˆ é™¤å¯¹è¯ '{thread_name}' å—ï¼Ÿæ­¤æ“ä½œæ— æ³•æ’¤é”€ã€‚")
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ç¡®è®¤åˆ é™¤", type="primary", use_container_width=True):
                    # è°ƒç”¨åˆ é™¤å‡½æ•°ï¼ˆç¨åå®ç°ï¼‰
                    delete_conversation_thread(st.session_state.thread_to_delete)
                    # é‡ç½®çŠ¶æ€
                    st.session_state.thread_to_delete = None
                    st.session_state.show_delete_confirm = False
                    # å¦‚æœåˆ é™¤çš„æ˜¯å½“å‰é€‰ä¸­çš„çº¿ç¨‹ï¼Œåˆ‡æ¢åˆ°å¦ä¸€ä¸ªçº¿ç¨‹æˆ–åˆ›å»ºæ–°çº¿ç¨‹
                    if st.session_state.current_thread_id == st.session_state.thread_to_delete:
                        if st.session_state.conversation_threads:
                            # åˆ‡æ¢åˆ°æœ€è¿‘çš„çº¿ç¨‹
                            st.session_state.current_thread_id = next(iter(st.session_state.conversation_threads))
                        else:
                            # åˆ›å»ºæ–°çº¿ç¨‹
                            st.session_state.current_thread_id = create_new_conversation_thread()
                    # åˆ·æ–°é¡µé¢
                    st.rerun()
            with col2:
                if st.button("å–æ¶ˆ", use_container_width=True):
                    # é‡ç½®çŠ¶æ€
                    st.session_state.thread_to_delete = None
                    st.session_state.show_delete_confirm = False
                    # åˆ·æ–°é¡µé¢
                    st.rerun()

    # æ˜¾ç¤º LLM æœåŠ¡çŠ¶æ€å’Œå¯¹è¯çº¿ç¨‹ç®¡ç†ï¼ˆåœ¨ä¾§è¾¹æ é¡¶éƒ¨ï¼‰
    llm_status = get_llm_status()
    with st.sidebar:
        st.header("LLM çŸ¥è¯†åº“åŠ©æ‰‹")
        
        # æ–°å¯¹è¯æŒ‰é’®
        if st.button("ğŸ’¬ æ–°å¯¹è¯", type="primary", use_container_width=True):
            thread_id, _ = create_new_conversation_thread(st.session_state.conversation_threads)
            st.session_state.current_thread_id = thread_id
            # åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºæ–°å¯¹è¯
            st.rerun()
        
        # å¯¹è¯çº¿ç¨‹åˆ—è¡¨
        st.subheader("å¯¹è¯å†å²")
        
        # å¯¹çº¿ç¨‹æŒ‰æœ€åæ›´æ–°æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        sorted_threads = sorted(
            st.session_state.conversation_threads.items(),
            key=lambda x: x[1].get('last_updated', ''),
            reverse=True
        )
        
        # æ˜¾ç¤ºçº¿ç¨‹åˆ—è¡¨
        for thread_id, thread in sorted_threads:
            is_active = thread_id == st.session_state.current_thread_id
            button_label = f"{thread['name']}"
            
            # ä½¿ç”¨åˆ—å¸ƒå±€æ˜¾ç¤ºçº¿ç¨‹åç§°å’Œåˆ é™¤æŒ‰é’®
            col1, col2 = st.columns([4, 1])
            with col1:
                if st.button(button_label, key=f"thread_{thread_id}", use_container_width=True):
                    st.session_state.current_thread_id = thread_id
                    # åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºé€‰ä¸­çš„å¯¹è¯
                    st.rerun()
            with col2:
                # æ·»åŠ åˆ é™¤æŒ‰é’®
                if st.button("ğŸ—‘ï¸", key=f"delete_thread_{thread_id}", use_container_width=True):
                    # æ ‡è®°è¦åˆ é™¤çš„çº¿ç¨‹ID
                    st.session_state.thread_to_delete = thread_id
                    # æ˜¾ç¤ºç¡®è®¤å¯¹è¯æ¡†
                    st.session_state.show_delete_confirm = True
                    # åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºç¡®è®¤å¯¹è¯æ¡†
                    st.rerun()
        
        st.divider()
        
        st.header("LLM æœåŠ¡çŠ¶æ€")
        if llm_status["current_service"] == "OpenAI-compatible API":
            st.success(f"âœ… **å½“å‰ä½¿ç”¨: {llm_status['current_service']}**")
            st.write(f"æ¨¡å‹: {llm_status['current_model']}")
            if llm_status["fallback_service"] != "æ— ":
                st.info(f"å›é€€æœåŠ¡: {llm_status['fallback_service']}")
        elif llm_status["current_service"] == "Ollama":
            st.info(f"â„¹ï¸ **å½“å‰ä½¿ç”¨: {llm_status['current_service']}**")
            st.write(f"æ¨¡å‹: {llm_status['current_model']}")
        else:
            st.error(f"âŒ **{llm_status['current_service']}**")
            st.warning("è¯·é…ç½® openai-compatible API æˆ–ç¡®ä¿ Ollama æ­£åœ¨è¿è¡Œ")
        
        # Display configuration details
        with st.expander("ğŸ“‹ é…ç½®è¯¦æƒ…"):
            st.write(f"**openai-compatible:** {'âœ… å·²é…ç½®' if llm_status['openai_configured'] else 'âŒ æœªé…ç½®'}")
            if not llm_status['openai_configured']:
                st.write("ç¼ºå°‘çš„é…ç½®:")
                if not llm_status.get('openai_api_key_set', False):
                    st.write("  - âŒ OPENAI_COMPATIBLE_API_KEY")
                st.write("")
                st.write("ğŸ’¡ **è§£å†³æ–¹æ³•:**")
                st.write("1. åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º `.env` æ–‡ä»¶")
                st.write("2. æ·»åŠ ä»¥ä¸‹é…ç½®:")
                st.code("""
OPENAI_COMPATIBLE_API_KEY=ä½ çš„APIå¯†é’¥
OPENAI_COMPATIBLE_MODEL=<model name>
                """, language="env")
            st.write(f"**Ollama:** {'âœ… å¯ç”¨' if llm_status['ollama_available'] else 'âŒ ä¸å¯ç”¨'}")
            st.write(f"**æœ€å¤§å¯¹è¯çº¿ç¨‹æ•°:** {MAX_CONVERSATION_THREADS}")
        
        st.divider()
    
    st.sidebar.header("Upload")
    st.sidebar.caption("æ”¯æŒä¸Šä¼ æœ€å¤š 5 ä¸ªæ–‡ä»¶ï¼ˆ.txt, .md, .pdf, .docxï¼‰")
    uploaded_files = st.sidebar.file_uploader(
        "Upload documents to index", 
        accept_multiple_files=True,
        type=['txt', 'md', 'pdf', 'docx']
    )
    
    if uploaded_files:
        # æ£€æŸ¥æ–‡ä»¶æ•°é‡
        if len(uploaded_files) > 5:
            st.sidebar.warning(f"âš ï¸ æ‚¨é€‰æ‹©äº† {len(uploaded_files)} ä¸ªæ–‡ä»¶ï¼Œå°†åªå¤„ç†å‰ 5 ä¸ª")
        
        # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
        with st.sidebar.expander(f"ğŸ“ å·²é€‰æ‹©æ–‡ä»¶ ({len(uploaded_files)} ä¸ª)"):
            for i, f in enumerate(uploaded_files[:5], 1):
                st.write(f"{i}. {f.name} ({f.size / 1024:.1f} KB)")
        
        if st.sidebar.button("Ingest", type="primary"):
            ingest_and_index(uploaded_files[:5])  # åªå¤„ç†å‰5ä¸ª

    # è¾“å…¥å®¹å™¨ç§»åˆ°é¡¶éƒ¨
    st.markdown('<div class="input-container">', unsafe_allow_html=True)
    
    # ä½¿ç”¨ session state è·Ÿè¸ªå½“å‰é—®é¢˜ï¼Œç¡®ä¿æ¯æ¬¡æ–°é—®é¢˜æ—¶éƒ½æ›´æ–°
    if 'last_question' not in st.session_state:
        st.session_state.last_question = ""
    
    # ä½¿ç”¨é»˜è®¤å€¼è€Œä¸æ˜¯æ»‘å—æ§ä»¶
    k = 4  # é»˜è®¤æ£€ç´¢4ä¸ªæ–‡æ¡£ç‰‡æ®µ
    min_similarity = 0.3  # é»˜è®¤æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼30%
    
    # åˆ›å»ºè‡ªå®šä¹‰è¾“å…¥æ¡†å’ŒæŒ‰é’®ç»„åˆ
    st.markdown('<div class="custom-input-wrapper">', unsafe_allow_html=True)
    
    # ä½¿ç”¨st.text_inputå¹¶è®¾ç½®keyå‚æ•°
    question = st.text_input(
        "",
        key="user_question",
        placeholder="æ‚¨çš„é—®é¢˜"
    )
    
    # ä½¿ç”¨Streamlitå®˜æ–¹æŒ‰é’®ï¼Œé€šè¿‡keyå’Œæ ·å¼ç±»è¿›è¡Œè‡ªå®šä¹‰
    st.markdown("""
    <style>
    /* ä¸ºStreamlitæŒ‰é’®æ·»åŠ è‡ªå®šä¹‰æ ·å¼ */
    .stButton > button {
        display: block;
        width: 100%;
        margin-top: 10px;
        padding: 8px 0;
        background-color: #1E88E5;
        color: white;
        border: none;
        border-radius: 4px;
        cursor: pointer;
    }
    
    .stButton > button:hover {
        background-color: #1565C0;
    }
    
    .stButton > button:active {
        background-color: #0D47A1;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # ä½¿ç”¨Streamlitå®˜æ–¹çš„st.buttonè€Œä¸æ˜¯è‡ªå®šä¹‰HTMLæŒ‰é’®
    ask_button = st.button("Ask", key="custom_ask_button")
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°é—®é¢˜
    is_new_question = question != st.session_state.last_question if question != st.session_state.last_question else True
    
    # ç§»é™¤è‡ªå®šä¹‰çš„Enteré”®äº‹ä»¶ç›‘å¬å™¨ï¼Œä½¿ç”¨StreamlitåŸç”ŸåŠŸèƒ½
    
    # ç¡®ä¿ä¾§è¾¹æ çš„IngestæŒ‰é’®å¯è§ï¼ˆå‰©ä½™çš„éšè—æ ·å¼ä¼šåœ¨é¡µé¢åº•éƒ¨å®šä¹‰ï¼‰
    st.markdown("""
    <style>
        # ç¡®ä¿ä¾§è¾¹æ çš„IngestæŒ‰é’®å¯è§
        .sidebar-content [data-testid="stButton"] {
            display: block !important;
        }
    </style>
    """, unsafe_allow_html=True)
    
    st.markdown('</div>', unsafe_allow_html=True)  # å…³é—­custom-input-wrapper
    st.markdown('</div>', unsafe_allow_html=True)  # å…³é—­input-container
    
    # æ·»åŠ é—®ç­”æ˜¾ç¤ºåŒºåŸŸï¼Œä½äºaskæŒ‰é’®ä¸‹æ–¹
    st.markdown('<div class="qa-display-area">', unsafe_allow_html=True)
    
    # è·å–å½“å‰çº¿ç¨‹çš„å¯¹è¯å†å²
    current_thread = st.session_state.conversation_threads.get(st.session_state.current_thread_id, {})
    conversation_history = current_thread.get('conversation_history', [])
    
    # å¦‚æœå¯¹è¯å†å²ä¸ºç©ºï¼Œæ·»åŠ ä¸€ä¸ªæ¬¢è¿æ¶ˆæ¯
    if not conversation_history:
        conversation_history = [{
            "role": "assistant",
            "content": "ğŸ‘‹ ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªåŸºäº LLM çš„çŸ¥è¯†åº“é—®ç­”åŠ©æ‰‹ã€‚è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼Œæˆ‘ä¼šæ ¹æ®çŸ¥è¯†åº“å†…å®¹ä¸ºä½ æä¾›å›ç­”ã€‚",
            "timestamp": "æ¬¢è¿æ¶ˆæ¯"
        }]
        # æ›´æ–°çº¿ç¨‹ä¿¡æ¯
        current_thread['conversation_history'] = conversation_history
        current_thread['last_updated'] = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
        st.session_state.conversation_threads[st.session_state.current_thread_id] = current_thread
        # ä¿å­˜å¯¹è¯çº¿ç¨‹
        save_conversation_threads(st.session_state.conversation_threads)
    
    # æ˜¾ç¤ºæœ€æ–°çš„é—®é¢˜å’Œç­”æ¡ˆï¼ˆå¦‚æœæœ‰ï¼‰
    if conversation_history:
        # è·å–æœ€è¿‘çš„å¯¹è¯ï¼ˆé—®é¢˜å’Œç­”æ¡ˆï¼‰
        recent_messages = conversation_history[-2:] if len(conversation_history) >= 2 else conversation_history
        
        for message in recent_messages:
            role = message.get("role", "user")
            content = message.get("content", "")
            
            # æ ¹æ®è§’è‰²é€‰æ‹©ä¸åŒçš„æ ·å¼ç±»
            message_class = "user-message" if role == "user" else "assistant-message"
            
            # æ˜¾ç¤ºæ¶ˆæ¯å†…å®¹
            st.markdown(f'<div class="message-card {message_class}">{content}</div>', unsafe_allow_html=True)
            
            # å¦‚æœæ˜¯åŠ©æ‰‹æ¶ˆæ¯ä¸”æœ‰æ¥æºä¿¡æ¯ï¼Œæ˜¾ç¤ºæ¥æº
            if role == "assistant" and "sources" in message and message["sources"]:
                st.markdown('<div class="sources-info">', unsafe_allow_html=True)
                st.markdown('**æ¥æº:**', unsafe_allow_html=True)
                for source in message["sources"]:
                    st.markdown(source, unsafe_allow_html=True)
                st.markdown('</div>', unsafe_allow_html=True)
    
    st.markdown('</div>', unsafe_allow_html=True)  # å…³é—­qa-display-area
    
    # æ£€æŸ¥æ˜¯å¦åº”è¯¥å¤„ç†é—®é¢˜ï¼ˆä½¿ç”¨StreamlitåŸç”ŸæŒ‰é’®è¿”å›å€¼ï¼‰
    if ask_button and question:
        # æ›´æ–°é—®é¢˜è®°å½•
        st.session_state.last_question = question
        # é‡ç½®è‡ªå®šä¹‰æŒ‰é’®ç‚¹å‡»çŠ¶æ€ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰
        if hasattr(st.session_state, 'custom_ask_clicked'):
            st.session_state.custom_ask_clicked = False
        
        start_time = time.time()
        
        # Retrieval phase - æ¯æ¬¡éƒ½ä¼šé‡æ–°æ£€ç´¢
        retrieve_start = time.time()
        store = get_store()
        
        # è·å–å½“å‰çº¿ç¨‹çš„å¯¹è¯å†å²
        current_thread = st.session_state.conversation_threads.get(st.session_state.current_thread_id, {})
        conversation_history = current_thread.get('conversation_history', [])
        
        # åˆ›å»ºå¢å¼ºçš„æŸ¥è¯¢ï¼ŒåŒ…å«æœ€è¿‘çš„å¯¹è¯å†å²ä¸Šä¸‹æ–‡
        enhanced_query = question
        recent_conversations = []
        
        # è·å–æœ€è¿‘çš„å¯¹è¯å†å²ï¼ˆæœ€å¤š2è½®å¯¹è¯ï¼‰
        if len(conversation_history) > 2:
            # ä»å†å²ä¸­æå–æœ€è¿‘çš„å¯¹è¯ï¼ˆè·³è¿‡å½“å‰é—®é¢˜å’Œæ¬¢è¿æ¶ˆæ¯ï¼‰
            i = len(conversation_history) - 1
            while i >= 0 and len(recent_conversations) < 4:  # æœ€å¤š4æ¡æ¶ˆæ¯ï¼ˆ2è½®å¯¹è¯ï¼‰
                if conversation_history[i].get('role') in ['user', 'assistant'] and \
                   conversation_history[i].get('timestamp') != 'æ¬¢è¿æ¶ˆæ¯':
                    recent_conversations.append(conversation_history[i])
                i -= 1
            
            # å°†æœ€è¿‘çš„å¯¹è¯æŒ‰æ—¶é—´é¡ºåºæ’åˆ—ï¼ˆæœ€æ—©çš„åœ¨å‰ï¼‰
        recent_conversations.reverse()
        
        # æ„å»ºå¢å¼ºçš„æŸ¥è¯¢ï¼ŒåŒ…å«æœ€è¿‘çš„å¯¹è¯å†å²
        conversation_context = "\n".join([
            f"{'ç”¨æˆ·' if msg.get('role') == 'user' else 'AI'}: {msg.get('content', '')}"
            for msg in recent_conversations[-4:]  # æœ€å¤šä½¿ç”¨æœ€è¿‘4æ¡æ¶ˆæ¯
        ])
        
        if conversation_context:
            enhanced_query = f"{question}\n\næœ€è¿‘çš„å¯¹è¯ä¸Šä¸‹æ–‡:\n{conversation_context}"
            logger.info("ä½¿ç”¨å¢å¼ºæŸ¥è¯¢ï¼ŒåŒ…å«æœ€è¿‘å¯¹è¯å†å²")
        
        # å…ˆæ£€ç´¢åŸå§‹ç»“æœï¼ˆä¸åº”ç”¨é˜ˆå€¼ï¼‰ç”¨äºè°ƒè¯•
        raw_hits = store.query(enhanced_query, k=k * 5, min_similarity=0.0)
        
        # ç„¶ååº”ç”¨é˜ˆå€¼è¿‡æ»¤
        hits = store.query(enhanced_query, k=k, min_similarity=min_similarity)
        retrieve_time = time.time() - retrieve_start
        
        # è®°å½•æ£€ç´¢ç»“æœä¿¡æ¯åˆ°ç»ˆç«¯æ—¥å¿—
        if not hits:
            logger.warning(f"æ²¡æœ‰æ£€ç´¢åˆ°ä»»ä½•ç›¸å…³å†…å®¹ï¼å½“å‰æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼: {min_similarity:.0%}")
            if raw_hits:
                logger.info(f"åŸå§‹æ£€ç´¢ç»“æœï¼ˆæœªè¿‡æ»¤ï¼Œå…± {len(raw_hits)} ä¸ªï¼‰:")
                for i, h in enumerate(raw_hits[:5], 1):
                    text = h.get('document') or h.get('text') or ""
                    metadata = h.get('metadata', {})
                    similarity = h.get('similarity', 0)
                    source = metadata.get('source', 'æœªçŸ¥')
                    source_type = "å¯¹è¯å†å²" if source == "conversation_history" else "æ–‡æ¡£"
                    logger.info(f"åŸå§‹ç‰‡æ®µ {i}: ç›¸ä¼¼åº¦: {similarity:.2%}, æ¥æºç±»å‹: {source_type}, æ¥æº: {source}")
        else:
            logger.info(f"æ£€ç´¢åˆ° {len(hits)} ä¸ªç‰‡æ®µï¼ˆå·²è¿‡æ»¤ç›¸ä¼¼åº¦ < {min_similarity:.0%} çš„ç‰‡æ®µï¼‰:")
            for i, h in enumerate(hits, 1):
                text = h.get('document') or h.get('text') or ""
                metadata = h.get('metadata', {})
                similarity = h.get('similarity', 0)
                source = metadata.get('source', 'æœªçŸ¥')
                source_type = "å¯¹è¯å†å²" if source == "conversation_history" else "æ–‡æ¡£"
                logger.info(f"ç‰‡æ®µ {i}: ç›¸ä¼¼åº¦: {similarity:.2%}, æ¥æºç±»å‹: {source_type}, æ¥æº: {source}, å†…å®¹é•¿åº¦: {len(text)} å­—ç¬¦")
        
        # æ„å»ºæç¤ºè¯ï¼ŒåŒ…å«å¯¹è¯å†å²ä¸Šä¸‹æ–‡
        prompt_start = time.time()
        
        # å‡†å¤‡å¯¹è¯å†å²ä¸Šä¸‹æ–‡
        conversation_history_context = ""
        if len(conversation_history) > 2:
            # è·å–æœ€è¿‘çš„å¯¹è¯å†å²ï¼ˆæœ€å¤š3è½®å¯¹è¯ï¼‰
            recent_history = []
            i = len(conversation_history) - 1  # è·³è¿‡å½“å‰é—®é¢˜
            while i >= 0 and len(recent_history) < 6:  # æœ€å¤š6æ¡æ¶ˆæ¯ï¼ˆ3è½®å¯¹è¯ï¼‰
                if conversation_history[i].get('role') in ['user', 'assistant'] and \
                   conversation_history[i].get('timestamp') != 'æ¬¢è¿æ¶ˆæ¯':
                    recent_history.append(conversation_history[i])
                i -= 1
            
            # æŒ‰æ—¶é—´é¡ºåºæ’åˆ—
            recent_history.reverse()
            
            # æ„å»ºå¯¹è¯å†å²ä¸Šä¸‹æ–‡
            conversation_history_context = "\n\nå¯¹è¯å†å²ä¸Šä¸‹æ–‡:\n" + "\n".join([
                f"{'ç”¨æˆ·' if msg.get('role') == 'user' else 'AI'}: {msg.get('content', '')}"
                for msg in recent_history[-6:]
            ])
        
        if not hits:
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ã€‚
ä½ çš„ä»»åŠ¡æ˜¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
è¯·è€ƒè™‘å¯¹è¯å†å²ä¸Šä¸‹æ–‡ï¼Œå°½å¯èƒ½è¿è´¯åœ°å›åº”ç”¨æˆ·çš„é—®é¢˜ã€‚
å¦‚æœæ²¡æœ‰è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œè¯·ç¤¼è²Œåœ°å‘Šè¯‰ç”¨æˆ·ã€‚
"""
            prompt = f"""{system_prompt}
{conversation_history_context}

ç”¨æˆ·é—®é¢˜: {question}
"""
        else:
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ã€‚
ä½ çš„ä»»åŠ¡æ˜¯åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å’Œå¯¹è¯å†å²å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
è¯·ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼Œè¯­è¨€è¦è‡ªç„¶ã€å‹å¥½ã€‚
è¯·è€ƒè™‘å¯¹è¯çš„è¿è´¯æ€§ï¼Œå‚è€ƒä¹‹å‰çš„å¯¹è¯å†…å®¹ã€‚
è¯·å°½å¯èƒ½ç®€æ´åœ°å›ç­”ï¼Œä¸è¦åšè¿‡å¤šçš„é¢å¤–æ‰©å±•ã€‚
è¯·ä½¿ç”¨æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„å†…å®¹ã€‚
å¦‚æœä¸Šä¸‹æ–‡ä¿¡æ¯ä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œè¯·å¦‚å®è¯´æ˜ã€‚
è¯·åœ¨å›ç­”çš„æœ€åä½¿ç”¨ <sources> æ ‡ç­¾åˆ—å‡ºä½ å‚è€ƒçš„å†…å®¹æ¥æºã€‚
"""
            
            # æ„å»ºä¸Šä¸‹æ–‡
            context = "\n\n".join([
                f"ç‰‡æ®µ {i + 1}:\n{h.get('document') or h.get('text') or ''}" 
                for i, h in enumerate(hits)
            ])
            
            prompt = f"""{system_prompt}

ä¸Šä¸‹æ–‡ä¿¡æ¯:
{context}
{conversation_history_context}

ç”¨æˆ·é—®é¢˜: {question}
"""
        
        prompt_time = time.time() - prompt_start
        
        # è®°å½•promptå’Œæ£€ç´¢ä¿¡æ¯åˆ°ç»ˆç«¯æ—¥å¿—
        logger.info(f"Prompt é•¿åº¦: {len(prompt)} å­—ç¬¦ | æ£€ç´¢è€—æ—¶: {retrieve_time:.2f}ç§’ | æ£€ç´¢åˆ° {len(hits)} ä¸ªç‰‡æ®µï¼ˆé˜ˆå€¼: {min_similarity:.0%})")
        logger.debug(f"å®Œæ•´Prompt: {prompt}")
        
        # LLM generation phase
        with st.spinner("ğŸ¤– æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ..."):
            generate_start = time.time()
            try:
                answer, service_used = generate(prompt)
                generate_time = time.time() - generate_start
                total_time = time.time() - start_time
                
                # è®°å½•æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯åˆ°ç»ˆç«¯
                logger.info(f"æ€§èƒ½ç»Ÿè®¡ - å‘é‡æ£€ç´¢: {retrieve_time:.2f}ç§’, Promptæ„å»º: {prompt_time:.2f}ç§’, LLMç”Ÿæˆ: {generate_time:.2f}ç§’ ({service_used}), æ€»è€—æ—¶: {total_time:.2f}ç§’")
                
                # è·å–å½“å‰æ—¶é—´æˆ³
                current_time = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
                
                    # è·å–å½“å‰çº¿ç¨‹
                current_thread = st.session_state.conversation_threads.get(st.session_state.current_thread_id, {})
                conversation_history = current_thread.get('conversation_history', [])
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯çº¿ç¨‹çš„ç¬¬ä¸€ä¸ªé—®é¢˜ï¼Œå¦‚æœæ˜¯åˆ™æ›´æ–°çº¿ç¨‹åç§°
                if len(conversation_history) == 1 and conversation_history[0].get('role') == 'assistant':
                    update_thread_name(st.session_state.conversation_threads, st.session_state.current_thread_id, question)
                
                # å°†é—®é¢˜å’Œç­”æ¡ˆæ·»åŠ åˆ°å¯¹è¯å†å²
                conversation_history.append({
                    "role": "user",
                    "content": question,
                    "timestamp": current_time
                })
                
                # å‡†å¤‡æ¥æºä¿¡æ¯
                sources = []
                for h in hits:
                    metadata = h.get("metadata", {})
                    similarity = h.get('similarity', 0)
                    sources.append(f"- {metadata.get('source', 'æœªçŸ¥')} (å— {metadata.get('chunk_index', '?')}, ç›¸ä¼¼åº¦: {similarity:.2%})")
                
                conversation_history.append({
                    "role": "assistant", 
                    "content": answer,
                    "sources": sources,
                    "timestamp": current_time
                })
                
                # æ›´æ–°çº¿ç¨‹ä¿¡æ¯
                current_thread['conversation_history'] = conversation_history
                current_thread['last_updated'] = current_time
                st.session_state.conversation_threads[st.session_state.current_thread_id] = current_thread
                
                # ä¿å­˜å¯¹è¯çº¿ç¨‹åˆ°æœ¬åœ°æ–‡ä»¶
                save_conversation_threads(st.session_state.conversation_threads)
                
                # ä¹Ÿä¿å­˜åˆ°ä¼ ç»Ÿçš„å¯¹è¯å†å²æ–‡ä»¶ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
                save_conversation_history(conversation_history)
                
                # åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºæ–°çš„å¯¹è¯å†…å®¹
                st.rerun()
                
            except Exception as e:
                logger.error(f"LLM generation error: {e}")
                st.error(f"LLM generation error: {e}")



if __name__ == "__main__":
    main()
