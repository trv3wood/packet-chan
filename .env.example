# Chroma settings
CHROMA_PERSIST_DIR=./chroma_db

# Ollama local model name (e.g. llama2, vicuna, etc.)
OLLAMA_MODEL=llama2
# Optional: Ollama host/port if using REST API or proxy
OLLAMA_HOST=http://localhost:11434

# OpenAI fallback (optional)
OPENAI_API_KEY=
